{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Project 3: Neural Temporal Point Process (10 points)\n",
    "\n",
    "This project will be to implement a simple autoregressive neural TPP. This project is seperated into 4 sub-tasks:\n",
    "\n",
    "1. Implement the utility functions to handle batches of variable length event sequences.\n",
    "2. Implement an RNN-based encoder for the event history $H_i$ to be represented with a fixed-dimensional vector $c_i \\in \\mathbb{R}^d$ (often called “context embedding” or “history embedding”).\n",
    "3. Implement a conditional distribution in pytorch to parameterize the PDF $f^{*}(\\tau)$ of the TPP.\n",
    "4. Compute the Log-Likelihood of the event sequence $\\mathbf{t}$ for training.\n",
    "\n",
    "## Your task\n",
    "Complete the missing code. Make sure that all the functions follow the provided specification, i.e. the output of the function exactly matches the description in the docstring. \n",
    "\n",
    "Do not add or modify any code outside of the following comment blocks\n",
    "```\n",
    "##########################################################\n",
    "# YOUR CODE HERE\n",
    ".....\n",
    "##########################################################\n",
    "```\n",
    "\n",
    "The following things are **NOT** allowed:\n",
    "- Using additional `import` statements\n",
    "- Copying / reusing code from other sources (e.g. code by other students)\n",
    "\n",
    "If you plagiarize even for a single project task, you won't be eligible for the bonus this semester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Utility functions (2 pt.):\n",
    "\n",
    "Remember that each realization of a TPP can be represented by a strictly increasing sequence of arrival times $(t_1 , \\cdots , t_{N} )$ where $t_i \\in [0, T]$. However, we will instead consider the inter-event times $(\\tau_1 , \\cdots , \\tau_{N+1} )$ computed as $\\tau_i = t_i − t_{i−1}$ (assuming $t_0 = 0$ and $t_{N+1} = T$). \n",
    "\n",
    "\n",
    "To train the Neural TPP we will further have to work with batches of inter-event sequences in parallel. Here, we will have to implement a padding procedure to batch the sequences, as the sequences are of different lengths. \n",
    "\n",
    "1. Implement the function `get_tau` in `tpp.utils` to compute the inter-event times for a tensor of arrival times. You are free to implement it from scratch or use any pytorch function.\n",
    "\n",
    "2. Implement `get_sequence_batch` in `tpp.utils` to batch a list of temporal point process instances represented by their interevent times given by `tpp.utils.get_tau`. This will include zero-padding the sequences. In order to remember which element of the padded sequence is \"actual\" data you will have to return a boolean mask. Again you are free to implement it yourself or use any pytorch function.\n",
    "\n",
    "A visual summary of this subtask is represented in the following figure:\n",
    "![image](data/preprocess_times.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrival times: [tensor([1.0000, 2.0000, 3.0000, 7.0000, 9.0000, 9.5000]), tensor([2., 4., 6., 7., 8.])]\n",
      "End time: tensor([10.])\n",
      "Inter-event times (tau): [tensor([1.0000, 1.0000, 1.0000, 4.0000, 2.0000, 0.5000, 0.5000]), tensor([2., 2., 2., 1., 1., 2.])]\n",
      "tensor([[1.0000, 1.0000, 1.0000, 4.0000, 2.0000, 0.5000, 0.5000],\n",
      "        [2.0000, 2.0000, 2.0000, 1.0000, 1.0000, 2.0000, 0.0000]])\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True, False]])\n"
     ]
    }
   ],
   "source": [
    "# import utility functions\n",
    "from tpp.utils import get_tau, get_sequence_batch\n",
    "# load toy data\n",
    "# Test the get_tau function\n",
    "arrival_times = [torch.tensor([1.0, 2.0, 3.0, 7.0, 9.0, 9.5], dtype=torch.float32), torch.tensor([2.0, 4.0, 6.0, 7.0, 8.0], dtype=torch.float32)]  # Example tensor with multiple instances\n",
    "t_end = torch.tensor([10.0], dtype=torch.float32)  # Ensure t_end is of shape [1]\n",
    "\n",
    "# Call the get_tau function\n",
    "tau = [get_tau(t, t_end) for t in arrival_times]\n",
    "times, mask = get_sequence_batch(tau)\n",
    "# Print the results\n",
    "print(\"Arrival times:\", arrival_times)\n",
    "print(\"End time:\", t_end)\n",
    "print(\"Inter-event times (tau):\", tau)\n",
    "print(times)\n",
    "print(mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encoder (3 pt.):\n",
    "\n",
    "\n",
    "We will encode each inter-event time as $(\\tau_i, log(\\tau_i))$ to attain a two-dimensional representation $x_i \\in \\mathbb{R}^2$. Thus, our history $H_i$ can be represented by a sequence of vectors $(x_1,\\cdots,x_{N+1})$. \n",
    "\n",
    "Next we will obtain the history embedding $c_i \\in \\mathbb{R}^d$ with a simple RNN. We initialize the first context vector to all zeros $c_1 = 0$. We define the other context vectors $c_i$ recursively using the RNN update equation\n",
    "$c_{i+1} = tanh(W^{input} x_i + W^{update} c_i + b)$.\n",
    "\n",
    "1. Implement the method `NeuralTPP.encode` to encode the batch of interevent times as $(\\tau_i, log(\\tau_i))$ and attain $x_i$.\n",
    "\n",
    "2. Set-up the single layer RNN self.embedding_rnn with $d$ = hidden_dim in `NeuralTPP.__init__`.\n",
    "\n",
    "3. Apply the encoding and RNN to the inter-event times to attain the history embeddings $(c_1,\\cdots, c_N)$ in `NeuralTPP.embed_history`. Note, that the context starts with $c_1$ and ends with $c_N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrival times: [tensor([1.0000, 2.0000, 3.0000, 7.0000, 9.0000, 9.5000]), tensor([2., 4., 6., 7., 8.])]\n",
      "End time: tensor([10.])\n",
      "Inter-event times (tau): [tensor([1.0000, 1.0000, 1.0000, 4.0000, 2.0000, 0.5000, 0.5000]), tensor([2., 2., 2., 1., 1., 2.])]\n",
      "tensor([[1.0000, 1.0000, 1.0000, 4.0000, 2.0000, 0.5000, 0.5000],\n",
      "        [2.0000, 2.0000, 2.0000, 1.0000, 1.0000, 2.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# import utility functions\n",
    "from tpp.utils import get_tau, get_sequence_batch\n",
    "from tpp.model import NeuralTPP  # Import the NeuralTPP class from tpp.model\n",
    "# load toy data\n",
    "# Test the get_tau function\n",
    "arrival_times = [torch.tensor([1.0, 2.0, 3.0, 7.0, 9.0, 9.5], dtype=torch.float32), torch.tensor([2.0, 4.0, 6.0, 7.0, 8.0], dtype=torch.float32)]  # Example tensor with multiple instances\n",
    "t_end = torch.tensor([10.0], dtype=torch.float32)  # Ensure t_end is of shape [1]\n",
    "\n",
    "# Call the get_tau function\n",
    "tau = [get_tau(t, t_end) for t in arrival_times]\n",
    "times, mask = get_sequence_batch(tau)\n",
    "neural_tpp = NeuralTPP(hidden_dim=2)\n",
    "loss = neural_tpp.log_likelihood(times, mask)\n",
    "# Print the results\n",
    "print(\"Arrival times:\", arrival_times)\n",
    "print(\"End time:\", t_end)\n",
    "print(\"Inter-event times (tau):\", tau)\n",
    "print(times)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conditional density (3 pt.)\n",
    "\n",
    "We model our conditional density of the positive inter-event times with a Log-Normal distribution:\n",
    "\n",
    "$f^{*}(\\tau_i) = Lognormal(\\tau_i| \\mu_i, \\sigma_i),$\n",
    "\n",
    "where $\\mu_i = v^T_{mean}c_i+b_{mean}$ and $\\sigma_i = exp(v^T_{std}c_i+b_{std})$. Note, that both the mean and standard deviation are parameterized by an affine transform, that can be batched and implemented by a single MLP to attain $\\mu$ and $log(\\sigma)$ simultaneously.\n",
    "\n",
    "1. Intitialize the single Layer MLP that maps from $c_i$ to $\\mu$ and $log(\\sigma)$ as `self.linear` in `NeuralTPP.__init__`.\n",
    "\n",
    "\n",
    "2. Implement the method `get_distribution_parameters` that applies `self.linear` and returns the batched $\\mu$ and $\\sigma$ for all events.\n",
    "\n",
    "\n",
    "3. Initialize the LogNormal distribution in `get_distributions` for the given batched $\\mu$ and $\\sigma$ of all events. For an introduction to shapes and batching for pytorch distributions please refer to: https://bochang.me/blog/posts/pytorch-distributions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Log-Likelihood (2 pts.)\n",
    "\n",
    "The log-likelihood for an event sequence $\\mathbf{t}$ of length $N$ is given by:\n",
    "\n",
    "$log p(\\mathbf{t}) = \\left[ \\sum^N_{i=1} log f^{*}(\\tau_i)\\right] + log S(\\tau_{N+1}| c_{N+1}),$\n",
    "\n",
    "where $S$ is the survival function.\n",
    "\n",
    "1. Implement the first half of the log-likelihood in `NeuralTPP.get_log_densities` for the batched event sequences.\n",
    "\n",
    "2. The second half of the log-likelihood, i.e., the evaluation of the survival function is to be implemented in `NeuralTPP.get_log_survival_prob`. Note that Pytorch distributions don’t implement the logarithm of the survival function, but you can easily compute it as log(1 - cdf(t)) using the cdf method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpp.model import NeuralTPP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and prepare variable length sequences for batched processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load toy data\n",
    "data = torch.load(\"data/hawkes.pkl\")\n",
    "\n",
    "arrival_times = data[\"arrival_times\"]\n",
    "t_end = data[\"t_end\"]\n",
    "\n",
    "# compute interevent times and batch sequences\n",
    "tau = [get_tau(t, t_end) for t in arrival_times]\n",
    "times, mask = get_sequence_batch(tau)\n",
    "\n",
    "# normalize inter event times [0,1]\n",
    "times = times/t_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model on the data\n",
    "\n",
    "The expected behaviour of a correctly implemented neural TPP would be to overfit the training set, leading to a very negative NLL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4999 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "torch.Size([10, 147])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Value is not broadcastable with batch_shape+event_shape: torch.Size([10]) vs torch.Size([10, 147]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tepoch:\n\u001b[0;32m      9\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlog_likelihood(times, mask)\n\u001b[0;32m     11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mloss\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     12\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mlgs\\Lib\\site-packages\\typeguard\\__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[1;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[1;32m~\\AMLGS\\mlgs24ex3-ge74wan\\tpp\\model.py:65\u001b[0m, in \u001b[0;36mNeuralTPP.log_likelihood\u001b[1;34m(self, times, mask)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# calculate negative log_likelihood\u001b[39;00m\n\u001b[0;32m     64\u001b[0m log_density \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_log_density(dist, times, mask)\n\u001b[1;32m---> 65\u001b[0m log_survival \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_log_survival_prob(dist, times, mask)\n\u001b[0;32m     67\u001b[0m log_likelihood \u001b[38;5;241m=\u001b[39m log_density \u001b[38;5;241m+\u001b[39m log_survival\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_likelihood\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mlgs\\Lib\\site-packages\\typeguard\\__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1031\u001b[0m memo \u001b[38;5;241m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[1;32m-> 1033\u001b[0m retval \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[1;32m~\\AMLGS\\mlgs24ex3-ge74wan\\tpp\\model.py:145\u001b[0m, in \u001b[0;36mNeuralTPP.get_log_survival_prob\u001b[1;34m(self, distribution, times, mask)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(times_last\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28mprint\u001b[39m(times\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 145\u001b[0m cdf_last \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mcdf(times_last)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Compute the survival probability\u001b[39;00m\n\u001b[0;32m    148\u001b[0m survival_prob_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m cdf_last\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mlgs\\Lib\\site-packages\\torch\\distributions\\transformed_distribution.py:201\u001b[0m, in \u001b[0;36mTransformedDistribution.cdf\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    199\u001b[0m     value \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39minv(value)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_dist\u001b[38;5;241m.\u001b[39m_validate_sample(value)\n\u001b[0;32m    202\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_dist\u001b[38;5;241m.\u001b[39mcdf(value)\n\u001b[0;32m    203\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_monotonize_cdf(value)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mlgs\\Lib\\site-packages\\torch\\distributions\\distribution.py:297\u001b[0m, in \u001b[0;36mDistribution._validate_sample\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(actual_shape), \u001b[38;5;28mreversed\u001b[39m(expected_shape)):\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m j \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[1;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    298\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue is not broadcastable with batch_shape+event_shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m         )\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m     support \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport\n",
      "\u001b[1;31mValueError\u001b[0m: Value is not broadcastable with batch_shape+event_shape: torch.Size([10]) vs torch.Size([10, 147])."
     ]
    }
   ],
   "source": [
    "model = NeuralTPP(hidden_dim=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "losses = []\n",
    "epochs = 5000\n",
    "\n",
    "with tqdm.tqdm(range(1, epochs), unit=\"epoch\") as tepoch:\n",
    "    for epoch in tepoch:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.log_likelihood(times, mask)\n",
    "        loss = -loss.mean()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tepoch.set_postfix(NLL=loss.item())\n",
    "\n",
    "plt.plot(range(1, epochs), losses)\n",
    "plt.ylabel(\"NLL\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "457a493feb279d2a8f7e805e1fb95d405b20bc23f0c027dbdc5dd17843557a95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
